{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkPglOS4w6Qr"
      },
      "source": [
        "**COLAB DEMO**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPnSsmYpP40A",
        "outputId": "ce7ebe84-2176-4049-9551-1900b53bc15b"
      },
      "outputs": [],
      "source": [
        "!git clone !git clone https://github.com/PanchengZhao/LAKE-RED.git
\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXCzp_noRoWY",
        "outputId": "cc12b9bb-7f28-4413-b1a7-be1998d59b68"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch transformers datasets evaluate accelerate nltk rouge_score\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -e .\n",
        "!pip install -q git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCApqQPT70T",
        "outputId": "a116c4a3-7746-4018-8d1f-afaa1217e01e"
      },
      "outputs": [],
      "source": [
        "!ls -la /content/LAKE-RED\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUdkQ5WZSwdP",
        "outputId": "a435d54d-a7cd-4898-8303-5fe5b14dd7a3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('LAKE-RED')\n",
        "!ls  # List files to verify we're in the right directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLtmepG4RpHw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXzBtQsdVUW0",
        "outputId": "3f589342-5336-47c5-b514-8c419266506c"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch Lightning and other dependencies based on the imports\n",
        "!pip install omegaconf pytorch-lightning tensorboard packaging pillow\n",
        "!pip install torch-fidelity  # For evaluation later\n",
        "\n",
        "# Make sure we have the right versions\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGBQnFdkVoYk",
        "outputId": "2ae7af9d-b032-4159-b7a8-682de4b2d32b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Download pretrained autoencoding model\n",
        "!wget -O /content/LAKE-RED/ldm/models/first_stage_models/vq-f4-noattn/model.ckpt \"https://heibox.uni-heidelberg.de/f/9c6681f64bb94338a069/?dl=1\"\n",
        "\n",
        "# Download pretrained LDM\n",
        "!wget -O /content/LAKE-RED/ldm/models/ldm/inpainting_big/last.ckpt \"https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1\"\n",
        "\n",
        "# Download LAKE-RED model\n",
        "!gdown \"https://drive.google.com/uc?id=18SsVydpBPVwYNS5G_D42Ns0TlHJRzM-D\" -O /content/LAKE-RED/ckpt/LAKERED.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5P9IPmcWAX9",
        "outputId": "3d8c8648-a3b5-4423-f56b-658b5aa43d66"
      },
      "outputs": [],
      "source": [
        "# Download the LAKE-RED dataset\n",
        "!gdown \"https://drive.google.com/uc?id=1M96ipKc3nVK_Q_LViM6t9UjT8sayRxuZ\" -O /conent/LAKE-RED/lakered_dataset.zip\n",
        "!unzip -q lakered_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUtWakNoYmQi",
        "outputId": "f1686630-61f7-44f3-b047-0aae5b17a993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python inference_one_sample.py --image /content/LAKE-RED/demo/src/COD_CAMO_camourflage_00012.jpg \\\n",
            "                               --mask /content/LAKE-RED/demo/src/COD_CAMO_camourflage_00012.png \\\n",
            "                               --log_path /content/LAKE-RED/demo_res "
          ]
        }
      ],
      "source": [
        "!cat /content/LAKE-RED/demo.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or_pZq000sNr",
        "outputId": "d9ca599f-519f-428c-d745-6a0c663e8107"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/CompVis/latent-diffusion.git\n",
        "!git clone https://github.com/CompVis/taming-transformers\n",
        "!pip install -e ./taming-transformers\n",
        "!pip install ipywidgets omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append('./taming-transformers')\n",
        "\n",
        "from torch import inf\n",
        "!pip install taming-transformers\n",
        "!pip install taming-transformers-rom1504\n",
        "\n",
        "\n",
        "from taming.models import vqgan # checking correct import from taming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9L6YqYJaGbp",
        "outputId": "60804c37-68cf-4ab0-c27d-9fa5a3b67e6f"
      },
      "outputs": [],
      "source": [
        "# Downgrade PyTorch Lightning to version 1.9.0\n",
        "!pip install pytorch-lightning==1.9.0\n",
        "# Install additional dependencies\n",
        "!pip install albumentations omegaconf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsDULBfdxNUx"
      },
      "source": [
        "## running **demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlxl9gs2cJfY",
        "outputId": "f0f76fc4-c06c-4367-f000-f8db8ef76396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "CUDA initialized\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n",
            "\n",
            "GPU Memory after forced allocation:\n",
            "Allocated: 11.44482421875 MB\n",
            "Cached: 20.0 MB\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "Called with args:\n",
            "Namespace(yaml_path='ldm/models/ldm/inpainting_big/config_LAKERED.yaml', model_path='ckpt/LAKERED.ckpt', log_path='/content/LAKE-RED/demo_res', image='/content/LAKE-RED/demo/src/COD_CAMO_camourflage_00012.jpg', mask='/content/LAKE-RED/demo/src/COD_CAMO_camourflage_00012.png', batchsize=9, isReplace=False, dilate_kernel=2, Steps=50)\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 387.25 M params.\n",
            "Keeping EMAs of 433.\n",
            "making attention of type 'none' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'none' with 512 in_channels\n",
            "Using first stage also as cond stage.\n",
            "Restored from ckpt/LAKERED.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "GPU Memory after model initialization:\n",
            "Allocated: 3184.42431640625 MB\n",
            "Cached: 3266.0 MB\n",
            "\n",
            "GPU Memory after model loading:\n",
            "Allocated: 3184.42431640625 MB\n",
            "Cached: 3266.0 MB\n",
            "\n",
            "GPU Memory after data processing:\n",
            "Allocated: 3200.17431640625 MB\n",
            "Cached: 3288.0 MB\n",
            "\n",
            "GPU Memory after data processing:\n",
            "Allocated: 3191.92431640625 MB\n",
            "Cached: 3288.0 MB\n",
            "Encoding masked image...\n",
            "Encoded shape: torch.Size([1, 3, 128, 128])\n",
            "Interpolating mask...\n",
            "Interpolated mask shape: torch.Size([1, 1, 128, 128])\n",
            "Concatenating...\n",
            "Concatenated shape: torch.Size([1, 4, 128, 128])\n",
            "Sampling shape: (3, 128, 128)\n",
            "Expanded shape: torch.Size([9, 4, 128, 128])\n",
            "Starting DDIM sampling...\n",
            "Data shape for DDIM sampling is (9, 3, 128, 128), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [02:50<00:00,  3.42s/it]\n",
            "DDIM sampling completed successfully\n",
            "\n",
            "GPU Memory after sampling:\n",
            "Allocated: 3272.1484375 MB\n",
            "Cached: 3670.0 MB\n"
          ]
        }
      ],
      "source": [
        "%cd /content/LAKE-RED\n",
        "!sh demo.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7QFd45OxZ6J"
      },
      "source": [
        "running demo.sh directly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrzrB3HYOSvV",
        "outputId": "74dd6757-48b8-49ca-9e13-646d30fcb57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "CUDA initialized\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n",
            "\n",
            "GPU Memory after forced allocation:\n",
            "Allocated: 11.44482421875 MB\n",
            "Cached: 20.0 MB\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "Called with args:\n",
            "Namespace(yaml_path='ldm/models/ldm/inpainting_big/config_LAKERED.yaml', model_path='ckpt/LAKERED.ckpt', log_path='demo_res', image='demo/src/COD_CAMO_camourflage_00018.jpg', mask='demo/src/COD_CAMO_camourflage_00018.png', batchsize=9, isReplace=False, dilate_kernel=2, Steps=50)\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 387.25 M params.\n",
            "Keeping EMAs of 433.\n",
            "making attention of type 'none' with 512 in_channels\n",
            "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
            "making attention of type 'none' with 512 in_channels\n",
            "Using first stage also as cond stage.\n",
            "Restored from ckpt/LAKERED.ckpt with 0 missing and 0 unexpected keys\n",
            "\n",
            "GPU Memory after model initialization:\n",
            "Allocated: 3184.42431640625 MB\n",
            "Cached: 3266.0 MB\n",
            "\n",
            "GPU Memory after model loading:\n",
            "Allocated: 3184.42431640625 MB\n",
            "Cached: 3266.0 MB\n",
            "\n",
            "GPU Memory after data processing:\n",
            "Allocated: 3202.42431640625 MB\n",
            "Cached: 3288.0 MB\n",
            "\n",
            "GPU Memory after data processing:\n",
            "Allocated: 3193.17236328125 MB\n",
            "Cached: 3288.0 MB\n",
            "Encoding masked image...\n",
            "Encoded shape: torch.Size([1, 3, 128, 128])\n",
            "Interpolating mask...\n",
            "Interpolated mask shape: torch.Size([1, 1, 128, 128])\n",
            "Concatenating...\n",
            "Concatenated shape: torch.Size([1, 4, 128, 128])\n",
            "Sampling shape: (3, 128, 128)\n",
            "Expanded shape: torch.Size([9, 4, 128, 128])\n",
            "Starting DDIM sampling...\n",
            "Data shape for DDIM sampling is (9, 3, 128, 128), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "DDIM Sampler: 100% 50/50 [02:56<00:00,  3.53s/it]\n",
            "DDIM sampling completed successfully\n",
            "\n",
            "GPU Memory after sampling:\n",
            "Allocated: 3273.5234375 MB\n",
            "Cached: 3670.0 MB\n"
          ]
        }
      ],
      "source": [
        "%cd /content/LAKE-RED\n",
        "!python inference_one_sample.py --image demo/src/COD_CAMO_camourflage_00018.jpg \\\n",
        "                               --mask demo/src/COD_CAMO_camourflage_00018.png \\\n",
        "                               --log_path demo_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HAxyeD3xmUr"
      },
      "source": [
        "checking for gpu, image loading (not required to run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-L28y8pOkAh",
        "outputId": "3d426e5d-0b4e-4a72-d3a4-c421275fa541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr 29 15:48:24 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0             35W /   70W |       0MiB /  15360MiB |      9%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVtNnoDffpSP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM8AZcdPQVmI",
        "outputId": "04ff0aaf-2e06-49eb-d959-25849dbdf7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "img = cv2.imread('demo/src/COD_CAMO_camourflage_00012.jpg')\n",
        "print(img is not None)  # Should print True if image was read successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMAOEFipQZgv",
        "outputId": "ebb574aa-49d4-42e2-bd5e-04902c4a1051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(632, 420)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "img = Image.open('demo/src/COD_CAMO_camourflage_00012.jpg')\n",
        "print(img.size)  # Should print the image dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt3aweDgTUJe",
        "outputId": "bc30f7aa-e7cb-4523-b959-ae45e81674cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory allocated: 0.0 MB\n",
            "GPU Memory cached: 0.0 MB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"GPU Memory allocated:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
        "print(\"GPU Memory cached:\", torch.cuda.memory_reserved() / 1024**2, \"MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX372YS6TTt5",
        "outputId": "e3a9e0d2-a06b-4718-c7ab-2f4d64cf5dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 6.0G Jun 10  2024 ckpt/LAKERED.ckpt\n"
          ]
        }
      ],
      "source": [
        "!ls -lh ckpt/LAKERED.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qq4-4MTTTdk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
